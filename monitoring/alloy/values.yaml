alloy:
  alloy:
    extraPorts:
    - name: "otlp"
      port: 4318
      targetPort: 4318
      protocol: "TCP"
    configMap:
      create: true
      content: |-
        loki.write "main" {
          endpoint {
            url = "http://loki-gateway.monitoring.svc.cluster.local:80/loki/api/v1/push"
          }
        }

        // discovery.kubernetes allows you to find scrape targets from Kubernetes resources.
        // It watches cluster state and ensures targets are continually synced with what is currently running in your cluster.
        discovery.kubernetes "pod" {
          role = "pod"
        }

        // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
        // If no rules are defined, then the input targets are exported as-is.
        discovery.relabel "pod_logs" {
          targets = discovery.kubernetes.pod.targets

          // Label creation - "namespace" field from "__meta_kubernetes_namespace"
          rule {
            source_labels = ["__meta_kubernetes_namespace"]
            action = "replace"
            target_label = "namespace"
          }

          // Label creation - "pod" field from "__meta_kubernetes_pod_name"
          rule {
            source_labels = ["__meta_kubernetes_pod_name"]
            action = "replace"
            target_label = "pod"
          }

          // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
          rule {
            source_labels = ["__meta_kubernetes_pod_container_name"]
            action = "replace"
            target_label = "container"
          }

          // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
          rule {
            source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
            action = "replace"
            target_label = "app"
          }

          // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
          // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
          rule {
            source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
            action = "replace"
            target_label = "job"
            separator = "/"
            replacement = "$1"
          }

          // Label creation - "container" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
          // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
          rule {
            source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
            action = "replace"
            target_label = "__path__"
            separator = "/"
            replacement = "/var/log/pods/*$1/*.log"
          }

          // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
          rule {
            source_labels = ["__meta_kubernetes_pod_container_id"]
            action = "replace"
            target_label = "container_runtime"
            regex = "^(\\S+):\\/\\/.+$"
            replacement = "$1"
          }
        }

        // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
        loki.source.kubernetes "pod_logs" {
          targets    = discovery.relabel.pod_logs.output
          forward_to = [loki.process.pod_logs.receiver]
        }

        // loki.process receives log entries from other Loki components, applies one or more processing stages,
        // and forwards the results to the list of receivers in the component's arguments.
        loki.process "pod_logs" {
          stage.static_labels {
            values = {
              cluster = "test",
            }
          }

          forward_to = [loki.write.main.receiver]
        }

        loki.source.kubernetes_events "cluster_events" {
          job_name   = "integrations/kubernetes/eventhandler"
          log_format = "logfmt"
          forward_to = [
            loki.process.cluster_events.receiver,
          ]
        }

        // loki.process receives log entries from other loki components, applies one or more processing stages,
        // and forwards the results to the list of receivers in the component's arguments.
        loki.process "cluster_events" {
          forward_to = [loki.write.main.receiver]

          stage.static_labels {
            values = {
              cluster = "test",
            }
          }

          stage.labels {
            values = {
              kubernetes_cluster_events = "job",
            }
          }
        }

        // Creates a receiver for OTLP gRPC.
        // You can easily add receivers for other protocols by using the correct component
        // from the reference list at: https://grafana.com/docs/alloy/latest/reference/components/
        otelcol.receiver.otlp "otlp_receiver" {
          // Listen on all available bindable addresses on port 4317 (which is the
          // default OTLP gRPC port) for the OTLP protocol.
          http {
            endpoint = "0.0.0.0:4318"
          }

          // Output straight to the OTLP HTTP exporter. We would usually do some processing
          // first, most likely batch processing, but for this example we pass it straight
          // through.
          output {
            traces = [
              otelcol.processor.k8sattributes.default.input,
              otelcol.processor.transform.default.input,
            ]
          }
        }

        otelcol.processor.transform "default" {
          error_mode = "ignore"

          trace_statements {
            context = "resource"
            statements = [
              // We keep only the "service.name" and "special.attr" resource attributes,
              // because they are the only ones which otelcol.connector.spanmetrics needs.
              //
              // There is no need to list "span.name", "span.kind", and "status.code"
              // here because they are properties of the span (and not resource attributes):
              // https://github.com/open-telemetry/opentelemetry-proto/blob/v1.0.0/opentelemetry/proto/trace/v1/trace.proto
              `keep_keys(attributes, ["service.name", "special.attr"])`,
            ]
          }

          output {
            traces  = [otelcol.connector.spanmetrics.default.input]
          }
        }

        otelcol.connector.spanmetrics "default" {
          dimension {
            name = "http.status_code"
          }

          dimension {
            name = "http.method"
            default = "GET"
          }

          dimension {
            name = "http.route"
          }

          dimension {
            name = "special.attr"
          }

          histogram {
            explicit {
              buckets = ["50ms", "100ms", "250ms", "1s", "5s", "10s"]
            }
          }

          metrics_flush_interval = "5s"

          output {
            metrics = [otelcol.exporter.prometheus.default.input]
          }
        }

        otelcol.processor.k8sattributes "default" {
          extract {
            label {
              from      = "pod"
              key_regex = "(.*)/(.*)"
              tag_name  = "$1.$2"
            }

            metadata = [
              "k8s.namespace.name",
              "k8s.pod.name",
              "k8s.pod.uid",
            ]
          }

          output {
            traces  = [
              otelcol.exporter.otlphttp.tempo.input,
            ]
            metrics = [
              otelcol.exporter.prometheus.default.input,
            ]
          }
        }

        // Define an OTLP gRPC exporter to send all received traces to GET.
        // The unique label 'tempo' is added to uniquely identify this exporter.
        otelcol.exporter.otlphttp "tempo" {
          // Define the client for exporting.
          client {
            // Send to the locally running Tempo instance, on port 4317 (OTLP gRPC).
            endpoint = "http://tempo.monitoring.svc.cluster.local:4318"
            //tls {
            //  insecure = true
            //  insecure_skip_verify = true
            //}
          }
        }

        otelcol.exporter.prometheus "default" {
          forward_to = [prometheus.remote_write.prom.receiver]
        }

        prometheus.remote_write "prom" {
          endpoint {
            url = "http://prometheus-server.monitoring.svc.cluster.local/api/v1/push"
          }
        }

        otelcol.exporter.otlphttp "mimir" {
          client {
            endpoint = "http://mimir-nginx.monitoring.svc.cluster.local:80/otlp"
          }
        }
